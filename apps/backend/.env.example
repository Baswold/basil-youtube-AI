# ============================================
# Server Configuration
# ============================================
PORT=4000
NODE_ENV=development
CORS_ORIGIN=http://localhost:3000

# ============================================
# Feature Flags
# ============================================
# Set to 'true' to use real adapters (requires API keys)
# Set to 'false' to use mock adapters (development)
USE_REAL_ADAPTERS=false

# ============================================
# Adapter Provider Selection
# ============================================
STT_PROVIDER=assemblyai  # Options: assemblyai, google, whisper
TTS_PROVIDER=google      # Options: google, piper
GUEST_PROVIDER=groq      # Options: groq, together, local, openai

# ============================================
# API Keys (Required when USE_REAL_ADAPTERS=true)
# ============================================
ANTHROPIC_API_KEY=your_anthropic_api_key_here
ASSEMBLYAI_API_KEY=your_assemblyai_api_key_here
GROQ_API_KEY=your_groq_api_key_here

# Optional API Keys (only if using these providers)
TOGETHER_API_KEY=your_together_api_key_here
OPENAI_API_KEY=your_openai_api_key_here

# Google Cloud (uses GOOGLE_APPLICATION_CREDENTIALS env var for credentials)
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json

# ============================================
# Local Service Endpoints
# ============================================
WHISPER_ENDPOINT=http://localhost:8001/transcribe
LOCAL_LLAMA_ENDPOINT=http://localhost:8080/v1

# ============================================
# Piper TTS Configuration (if using local TTS)
# ============================================
PIPER_PATH=piper
PIPER_MODEL_PATH=./models/en_US-lessac-medium.onnx

# ============================================
# Model Configuration
# ============================================
GUEST_MODEL=llama-3.3-70b-versatile

# ============================================
# Storage Paths
# ============================================
RECORDING_DIR=./recordings
BRIEFINGS_DIR=./briefings
